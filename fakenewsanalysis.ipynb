{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import sqlite3\n",
    "import sklearn\n",
    "import datetime\n",
    "import json\n",
    "from string import punctuation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "# csv file is large so the field_size_limit must be increased\n",
    "# maxsize can't be converted to long because it is too large so try except decreases size until it works]\n",
    "\n",
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "\n",
    "while decrement:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        decrement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    \"\"\"Loads csv and saves data in a list of dictionaries\"\"\"\n",
    "    csv_list = []\n",
    "    with open(filename, encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            csv_list.append({\"author\": row[\"author\"], \"date\": row[\"published\"],\"title\": row[\"title\"], \"text\":row[\"text\"],\"site_url\": row[\"site_url\"], \"type\": row[\"type\"]})\n",
    "    return csv_list\n",
    "\n",
    "original_news_data = load_csv(\"fake.csv\")\n",
    "news_data = load_csv(\"fake.csv\")\n",
    "word_news_data = load_csv(\"fake.csv\") \n",
    "\n",
    "def remove_if_null(data):\n",
    "    \"\"\"Function that removes all values if one in that dictionary is missing\n",
    "    *not sure if I'll use this*\n",
    "    \"\"\"\n",
    "    to_remove = []\n",
    "    for dicts in data:\n",
    "        for key, value in dicts.items():\n",
    "            if(value == None):\n",
    "                to_remove.append(dicts)\n",
    "    for dicts in to_remove:\n",
    "        data.remove(dicts)\n",
    "        \n",
    "def load_domains(file):\n",
    "    \"\"\"loads the json file of domains\"\"\"\n",
    "    with open(file, 'r') as line:\n",
    "        domain = json.load(line)\n",
    "    return domain\n",
    "        \n",
    "domains = load_domains(\"sources.json\")\n",
    "  \n",
    "def fix_unknown_types(data, domains):\n",
    "    \"\"\"replaces the unknown-bs types with the type associated with the url\n",
    "    in the json file\"\"\"\n",
    "    for keys, values in domains.items():\n",
    "        for dicts in data:\n",
    "            if(dicts[\"type\"] == 'bs'):\n",
    "                if(dicts[\"site_url\"] == keys):\n",
    "                    dicts[\"type\"] = values[\"type\"]\n",
    "    return data\n",
    "                    \n",
    "news_data = fix_unknown_types(news_data, domains)\n",
    "\n",
    "def totals(data, sum_type):\n",
    "    \"\"\"Returns a descending sorted tuple that holds the counts of the type of data that is passed in\"\"\"\n",
    "    sum_dict = {}\n",
    "    for dicts in data:\n",
    "        if dicts[sum_type] in sum_dict.keys():\n",
    "            sum_dict[dicts[sum_type]] += 1\n",
    "        else:\n",
    "            sum_dict[dicts[sum_type]] = 1\n",
    "    \n",
    "    sum_dict = sorted(sum_dict.items(), key=lambda t : t[1], reverse=True)\n",
    "    return sum_dict\n",
    "\n",
    "#url_sums = totals(news_data, \"site_url\")\n",
    "\n",
    "#print(url_sums[:300])\n",
    "\n",
    "def date_time(data, news_type):\n",
    "    \"\"\"Takes data and data type and creates a list of datetime objects for graphing number of articles over time\n",
    "    valid types are: bias, bs, all...\n",
    "    \"\"\"\n",
    "    date_list_raw = []\n",
    "    date_list_cleaned = []\n",
    "    \n",
    "    # places dates in first, then loops through them again to clean them\n",
    "    if(news_type == \"all\"):\n",
    "        for dicts in data:\n",
    "            # must replace the : because theres no native +00:00 timezone directive in strptime, only +0000\n",
    "            x = dicts[\"date\"].replace(\":\",\"\")\n",
    "            y = x[17:-5]\n",
    "            x = x.replace(y, \"\")\n",
    "            date_list_raw.append(x)\n",
    "    else:\n",
    "        for dicts in data:\n",
    "            if(dicts[\"type\"] == news_type):\n",
    "                x = dicts[\"date\"].replace(\":\",\"\")\n",
    "                y = x[17:-5]\n",
    "                x = x.replace(y, \"\")\n",
    "                date_list_raw.append(x)\n",
    "                \n",
    "    for item in date_list_raw:  \n",
    "        date_list_cleaned.append(datetime.datetime.strptime(item, \"%Y-%m-%dT%H%M%S%z\"))\n",
    "    \n",
    "    return date_list_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_text_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-95b9c606f927>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mtitle_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_title_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_news_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mtext_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_text_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_news_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Title Counts\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitle_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_text_words' is not defined"
     ]
    }
   ],
   "source": [
    "to_ignore = 'in they you a not that who but were we from be their has your their than them with how the to this are as of â€“ and if or his her an have is on what no he she by for'\n",
    "\n",
    "def clean_words(data):\n",
    "    \"\"\"This function prepares the words in the 'text' and 'title' part of the data for a total word count analysis\"\"\"\n",
    "    exclude = set(punctuation)\n",
    "    for dicts in data:\n",
    "        text_replace = [ char for char in dicts[\"text\"] if char not in exclude ]\n",
    "        title_replace = [ char for char in dicts[\"title\"] if char not in exclude ]\n",
    "        # to rejoin the individual characters\n",
    "        text_replace = \"\".join(text_replace)\n",
    "        title_replace = \"\".join(title_replace)\n",
    "        # replaces the text in form \n",
    "        dicts[\"text\"] = text_replace.lower()\n",
    "        dicts[\"title\"] = title_replace.lower()\n",
    "    return data\n",
    "\n",
    "def count_title_words(data):\n",
    "    \"\"\"Counts the total number of words in the tile part of data\n",
    "    returns a sorted dictionary of words as keys and counts as values\"\"\"\n",
    "    title_dict = {}\n",
    "    for dicts in data:\n",
    "        list_words = dicts['title'].strip().split()\n",
    "        for word in list_words:\n",
    "            if word in title_dict.keys() and word not in to_ignore:\n",
    "                title_dict[word] += 1\n",
    "            elif word != None and word not in to_ignore:\n",
    "                title_dict.update({word:1})\n",
    "    title_dict = sorted(title_dict.items(), key=lambda t : t[1], reverse=True)\n",
    "    return title_dict\n",
    "\n",
    "word_news_data = clean_words(word_news_data)\n",
    "\n",
    "title_counts = count_title_words(word_news_data)\n",
    "text_counts = count_text_words(word_news_data)\n",
    "print(\"Title Counts\")\n",
    "for word in title_counts[:20]:\n",
    "    print(word[0] + \": \", word[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date = date_time(news_data, \"all\")\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "font = {'size':16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('figure', figsize=(10, 10))\n",
    "\n",
    "plt.hist(full_date,bins=30)\n",
    "plt.xlabel(\"Date of Articles\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.title(\"Histogram of All Articles Over Time\")\n",
    "plt.savefig('all_articles.png')\n",
    "plt.show()\n",
    "\n",
    "types = ['bs', 'bias','conspiracy', 'hate','satire','state','junksci','fake']\n",
    "\n",
    "x_label = \"Date of Articles\"\n",
    "y_label = \"Number of Articles\"\n",
    "title = \"Histogram of Articles Over Time: \"\n",
    "ext = \".png\"\n",
    "\n",
    "all_data = []\n",
    "all_data.append(full_date)\n",
    "for each in types:\n",
    "    fig_name = each + \".png\"\n",
    "    title = \"Histogram of Articles Over Time: \"\n",
    "    dates = date_time(news_data, each)\n",
    "    all_data.append(dates)\n",
    "    plt.hist(dates,bins=30)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    title = title + each\n",
    "    plt.title(title)\n",
    "    plt.savefig(fig_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_data(filename):    \n",
    "    emotions_dict = {'joy': 1,'anger': 2,'fear': 3,'sadness': 4,'guilt': 5,'shame':6,'disgust':7}\n",
    "    csv_list = []\n",
    "    list_1 = []\n",
    "    list_2 = []\n",
    "    \n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            list_1.append(emotions_dict[row['emotion']])\n",
    "            list_2.append(row['text'])\n",
    "            \n",
    "    csv_list.append(list_1)\n",
    "    csv_list.append(list_2)\n",
    "    return csv_list\n",
    "\n",
    "sentiment = get_sentiment_data(\"isear.csv\")\n",
    "\n",
    "    \n",
    "def add_sentiment(data, training_data):\n",
    "    \"\"\"Adds Naive Bayes sentiment analysis on the title of \n",
    "    each article, as well as the text. Returns a list of dictionaries with new\n",
    "    sentiment key/value pair. \n",
    "    \n",
    "    Training data is a list of lists\n",
    "    \"\"\"\n",
    "    emotions_dict = {'joy': 1,'anger': 2,'fear': 3,'sadness': 4,'guilt': 5,'shame':6,'disgust':7}\n",
    "    \n",
    "    sentiment = Pipeline([('vect', CountVectorizer()),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultinomialNB()),])\n",
    "    sentiment.fit(training_data[1],training_data[0])\n",
    "    \n",
    "    for dicts in data:\n",
    "        to_predict_text = []\n",
    "        to_predict_text.append(dicts['text'])\n",
    "        to_predict_title = []\n",
    "        to_predict_title.append(dicts['title'])\n",
    "        predicted_text = sentiment.predict(to_predict_text)\n",
    "        predicted_title = sentiment.predict(to_predict_title)\n",
    "        for keys, values in emotions_dict.items():\n",
    "            if values == predicted_text:\n",
    "                dicts[\"text_sentiment\"] = keys\n",
    "            if values == predicted_title:\n",
    "                dicts[\"title_sentiment\"] = keys\n",
    "    return data\n",
    "        \n",
    "new_data = add_sentiment(word_news_data, sentiment)\n",
    "\n",
    "title_sentiment = totals(new_data, 'title_sentiment')\n",
    "text_sentiment = totals(new_data, 'text_sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emotion = []\n",
    "title_totals = []\n",
    "title_sum = 0\n",
    "for each in title_sentiment:\n",
    "    title_emotion.append(each[0])\n",
    "    title_totals.append(each[1]/12999)\n",
    "    \n",
    "text_emotion = []\n",
    "text_totals = []\n",
    "text_sum = 0\n",
    "for each in text_sentiment:\n",
    "    text_emotion.append(each[0])\n",
    "    text_totals.append(each[1]/12999)\n",
    "print(text_totals)\n",
    "print(title_totals)\n",
    "    \n",
    "    \n",
    "y_pos = np.arange(len(title_emotion))\n",
    " \n",
    "plt.bar(y_pos, title_totals, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, title_emotion)\n",
    "plt.ylabel('Percent of Emotion')\n",
    "plt.title('Emotions Classified to Article Title')\n",
    "plt.savefig(\"title_emotions.png\")\n",
    "plt.show()\n",
    "\n",
    "y_pos = np.arange(len(text_emotion))\n",
    " \n",
    "plt.bar(y_pos, text_totals, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, text_emotion)\n",
    "plt.ylabel('Percent of Emotion')\n",
    "plt.title('Emotions Classified to Article Text')\n",
    "plt.savefig(\"text_emotions.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
